{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyO94QBixZlsG2N8cpPQIx7A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/revans011/Minutes_of_Motion/blob/main/Canine_Minutes_in_Motion_Algorithm_II.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Minutes in Motion Algorithm"
      ],
      "metadata": {
        "id": "UwFRKNmwNDq_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##This notebook demonstrates how to use IMU data to count the number of minutes dogs move during a clinical trial"
      ],
      "metadata": {
        "id": "J1HedOD2Gf6F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Introduction\n",
        "Inertial measurement units (IMUs) contain accelerometers and gyroscopes, and researchers have used them to measure movement objectively in cat and dog orthopedic studies. (1,2) But IMUs measure in terms of gravities and angular velocities, which are not clinically relevant units. For clinical trials, clinically relevant units are necessary to show the treatment’s effect in practical ways that matter to dogs and their owners.\n",
        "\n",
        "This research demonstrates how to use raw IMU data to calculate the number of minutes dogs spend in motion. “Minutes of motion” are clinically relevant, objective measures: Researchers and owners hope less OA pain means more mobility and more time moving.\n",
        "\n",
        "This research is motivated by long-term orthopedic randomized clinical trials testing the effect of an analgesic for OA pain relief. If the treatment group has, on average, statistically significantly more minutes of motion than the control group, then we would conclude there is a treatment effect. More importantly, we could assess the magnitude of the clinical effect: Did the treatment dogs spend one hour moving more than control dogs per day, or one minute?\n",
        "\n",
        "My approach was to segment a dog’s IMU data into 7-second-long, non-overlapping windows, then classify each window as stationary or moving. The number of  \"moving\" windows multiplied by 7 seconds gives the total number of moving seconds for the dog over the trial. From there, dividing the total number of seconds by 60 seconds gives the dog’s minutes of motion during the trial.\n",
        "\n",
        "The key part of this research was developing a classifier that identifies the widows as stationary or moving. I developed the window classifier using IMU data from a Finnish study of dogs wearing collar IMUs while performing specified stationary tasks (standing, sitting, or lying down) and moving tasks (walking, trotting, playing, and treat searching) for three minutes each. (3,4) \n",
        "\n",
        "That data was used to develop decision boundaries that separate stationary-type IMU data from moving-type IMU data. The classifier classifies a window as stationary or moving depending on where the window's data falls among the boundaries.\n",
        "\n",
        "The simulation results here depend on the Finnish data, but the basic algorithm does not. The algorithm could easily be generalized to different IMUs and species. All that is needed is a  window classifier. Researchers could use any other labeled training data in a supervised classifier or no training data and an unsupervised classifier.\n",
        "\n",
        "**Bibliography**\n",
        "\n",
        "1. Scott, R. M., Evans, R., and Conzemius, M. G. (2017). Efficacy of an oral nutraceutical for the treatment of canine osteo arthritis. Veterinary and Comparative Orthopaedics and Traumatology, 30(05), 318-323.\n",
        "\n",
        "2. Lascelles, B. D. X., Hansen, B. D., Roe, S., DePuy, V., Thomson, A., Pierce, C. C., and Rowinski, E. (2007). Evaluation of client?specific outcome measures and activity monitoring to measure pain relief in cats with osteoarthritis. Journal of Veterinary Internal Medicine, 21(3), 410-416\n",
        "\n",
        "3. Vehkaoja, Antti; Somppi, Sanni; Törnqvist, Heini; Valldeoriola Cardó, Anna; Kumpulainen, Pekka; Väätäjä, Heli; Majaranta, Päivi; Surakka, Veikko; Kujala, Miiamaaria; Vainio, Outi (2022), “Movement Sensor Dataset for Dog Behavior Classification”, Mendeley Data, V2, doi: 10.17632/vxhx934tbn.2\n",
        "\n",
        "4. Kumpulainen, P., Valldeoriola Cardó, A., Somppi, S., Törnqvist, H., Väätäjä, H., Majaranta, P., Gizatdinova, Y., Hoog Antink, C., Surakka, V., Kujala, M. V., Vainio, O., and Vehkaoja, A., Dog behavior classification with movement sensors placed on the harness and the collar, Applied Animal Behavior Science, 241 (2021): 105393.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8HfjiQZR6tas"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Results\n",
        "Over several simulations, ranging from 3 hours to 14 days, the Minutes-of-Motion Algorithm calculated the number of minutes to be between 0.1 percent and 2 percent of a dog's true __moving__ time. \n",
        "\n",
        "For example, when, on average, dogs are stationary 50 percent of the time in a three-hour IMU measurement session, (so moving 1.5 hours) the algorithm overestimated movement by a median of 2 minutes.\n",
        "\n",
        "The accuracy depends upon the kinds of activities that are simulated. There is higher accuracy when the types of movement are more different; for example, standing vs. walking is less accurate than sitting vs. trotting.\n",
        "\n",
        "The Minutes-of-Motion Algorithm takes only a few minutes to run, even on 45-dog, two-week data. On real data, the algorithm is time efficient. However, generating simulated data takes considerable time. The code below generates simulated as part of the Minutes-of-Motion algorithm.\n"
      ],
      "metadata": {
        "id": "FavOhyMkQS4n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Discussion\n",
        "I measured the algorithm's accuracy seems to depend on the number of true minutes in motion. More motion means better accuracy.\n",
        "\n",
        "The minutes-in-motion algorithm could distinguish between moving time and stationary time using a classifier trained on previous data, the Finnish dataset. The classifier training data was a subset of the Finnish data, and the simulated clinical trial data was constructed from another subset of the Finnish data. Both datasets had data from the same kind of IMU. Different IMUs may be calibrated differently, so researchers should use care to classify data from one type of IMU with data from another.\n",
        "\n",
        "But the Finnish data could be used to train classifiers for data from other IMUs. Normalizing the features, as was done here, is some protection against different calibrations. However, if the calibrations are markedly different on a normalized scale, or the IMUs measure differently, then the Finnish data should not be used to train the classifier. Instead, other calibrated data should be used to train a supervised classifier. \n"
      ],
      "metadata": {
        "id": "qNKyLYuRV9hm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##The Finnish Data\n",
        "I used a publicly available Finnish dataset for this simulation. The Finnish researchers recorded data at 100 Hz from 45 dogs wearing collar IMUs (ActiGraph GT9X Link, ActiGraph LLC, Florida, USA). There were about 3 minutes of data each for three stationary tasks (standing, sitting, or lying down) and four moving tasks (walking, trotting, playing, and treat searching), for a total of about 21 minutes of data for each dog. Two were measured twice, giving 42 minutes of data for those dogs)\n",
        "\n",
        "Random snippets of the 21-minute data were combined to simulate multi-day data (see below for a complete description).\n",
        "\n",
        "The Finnish IMU variables were accelerometer data in three dimensions and gyroscope data in three dimensions ($x,$,$y$,$z$). The gyroscope data adequately discriminated between stationary and moving tasks, so the noisier accelerometer data were not used in this simulation.\n",
        "\n",
        "[The original data description here](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8777071/)\n",
        "\n",
        "\n",
        "\n",
        "[The data is here](https://data.mendeley.com/datasets/vxhx934tbn/2)\n",
        "\n"
      ],
      "metadata": {
        "id": "oj4GPBzG6nmo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##The Algorithm\n",
        "\n",
        "In practice, the Minutes-in-Motion algorithm has three steps.\n",
        "1. Build a classifier that distinguishes moving motion from stationary motion.\n",
        "1. Apply that classifier to short windows of a dog's IMU data (e.g., 10-second windows) and classify each window as moving or stationary.\n",
        "1. Add up the number of moving windows and perform the appropriate arithmetic to find the number of minutes in motion. For example, there are $1.21 x 10^8$ time points in two weeks of IMU data (100Hz) from one dog. That's $1.21 x 10^6$ seconds or $1.21 x10^5$ 10-second windows. If they moved in half of the windows, that's $604800$ seconds, or $168.1$ hours of movement in two weeks. \n"
      ],
      "metadata": {
        "id": "lGrzYtd5K4CU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##The Classifier and Feature Engineering\n",
        "I used Scilit-Learn's AdaBoost classifier trained on the Finnish data, but other classifiers, including simple decision rules based on eyeballing the data, seemed to work.\n",
        "\n",
        "I trained the classifier omitting the \"treat-search\" task. The reason was that the classifier was trained on balanced data (half stationary, half moving). The choice was conservative because the treat-search IMU data had high values and is clearly distinguished from stationary IMU data. On the other hand, walking IMU values sometimes look like standing IMU values. Leaving walking out makes the classifier look better than it is. \n",
        "\n",
        "###Features\n",
        "I tried many summaries, IQR, other percentiles, and the mean, but the classifier used only the median, sometimes not even that. It rarely used the gyro RMS instead of the gyro $z$ dimension. Only gyroscope data was used as the accelerometer data didn't contribute to the classification. Feature engineering was as follows. First, I calculated the root mean square (RMS) of the gyro data and included it as data along with the gyroscope data ($x,$,$y$,$z$). Those four variables were summarized with medians within a task for each dog. That is, a dog's 3-minute task was summarized with four medians corresponding to the axes and the RMS. So, each dog had seven rows of data corresponding to the seven tasks and six columns of data: a column indicating the task (e.g., \"trot\"), a binary column indicating if that task was stationary or moving, and the four medians. The training set was 315 + 14 (7x45=315. Two dogs were assessed twice for 14) rows and six columns. "
      ],
      "metadata": {
        "id": "m-UVV-viRhRx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#The Simulation Method\n",
        "I didn't have real data, so I modified the algorithm slightly for this simulation. Instead of using all the Finnish data to train the classifier, I used a leave-one-out approach.\n",
        "\n",
        "The steps were,\n",
        "\n",
        "1. I simulated \"clinical trial\" long-term data movement data for each dog (see below).\n",
        "1. For each dog, the classifier was trained on the other 44 dogs. In other words, that particular dog was left out of the classifier training, and it didn't influence its window classifications.\n",
        "1. Minutes of motion were calculated for each dog and compared to the actual minutes of motion.\n",
        "\n",
        "\n",
        "Finally, the medians were normalized within dog using a minimax scaler. That way, dogs with different movement styles would be on the same scale.\n",
        "\n"
      ],
      "metadata": {
        "id": "3B2IDxdISwWK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#The Simulated data\n",
        "\n",
        "Each simulated dog's long-term data came from its doppelganger in the Finnish set. It was an iterative process. For a given dog, and a given clinical trial length (e.g., 14 days)\n",
        "\n",
        "1. I randomly selected a task using weighted sampling (see below)\n",
        "1. I selected a snippet length from 5 seconds to 3 minutes long\n",
        "1. I sampled a snippet of Finnish IMU data for that dog, task, and length.\n",
        "1. I repeated that process until the dog had at least the correct 14 days of data. \n",
        "\n",
        "Next, the extended data sequence was segmented into 7-second windows, meaning there were 700 data rows in each window. Each window was summarized like the training data, with the medians of the three axes and the RMS. Note that the task was ignored here because that data is missing in an actual clinical trial. \n",
        "\n",
        "Part of generating the simulated data was randomly choosing tasks in a way that mimicked real dogs. In the simulations, I generally weighted the dogs, so they had at least 50 percent stationary movement. "
      ],
      "metadata": {
        "id": "H85JVLiYSC9r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##The Analysis\n"
      ],
      "metadata": {
        "id": "lqAPzkoIJThi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Reads the real dogs from the Finnish study"
      ],
      "metadata": {
        "id": "QNTqBHJbf8Xs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "#this is for local runtime\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "#read the training set\n",
        "path2 = \"your_path_here\"\n",
        "finnish_dog_master = pd.read_csv(path2)\n",
        "\n",
        "\n",
        "\n",
        "import statistics\n",
        "import numpy as np\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n"
      ],
      "metadata": {
        "id": "3L6BWDJogeVm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da29663c-9205-42fa-837e-cb53882d3891"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/opt/anaconda3/lib/python3.9/site-packages/google/colab/data_table.py:30: UserWarning: IPython.utils.traitlets has moved to a top-level traitlets package.\n",
            "  from IPython.utils import traitlets as _traitlets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 15.4 s, sys: 1.18 s, total: 16.6 s\n",
            "Wall time: 16.8 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Some Functions"
      ],
      "metadata": {
        "id": "FDLxJJY9UFAj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "'''\n",
        "These functions are used to (a) make training data or (b) classify windows\n",
        "This calculates the median IMU data. '''\n",
        "\n",
        "\n",
        "def my_median(df_arg):\n",
        "  \n",
        "  df_abs = df_arg.abs()\n",
        "  df_abs_median = df_abs.median(numeric_only=True)**.001\n",
        "  \n",
        "  return df_abs_median\n",
        "\n",
        "#This is the minimax scaler\n",
        "def my_scaler(z):\n",
        "  return (z-z.min())/(z.max()-z.min())\n",
        "\n",
        "\n",
        "'''\n",
        "Samples a random span from 5sec to 3min  from the dog's entire dataset\n",
        "that way the data may cover changes in movement but stay contiguous, that is,\n",
        "not take a single observation from one movement. The problem with that is movement is defined\n",
        "by a sequence of observations, not just one'''\n",
        "\n",
        "def sample_movement(dogid,task):\n",
        "  dog_rows = finnish_dog[(finnish_dog['DogID']==dogid) & (finnish_dog['Task']==task)] #getting all rows with the same, randomly sampled dog\n",
        "  \n",
        "  sample_length = np.random.randint(500, (dog_rows.shape[0]-501)) #5 seconds to all but 5 seconds the entire movement (about 3 minutes)\n",
        "  sample_start = np.random.randint(0, dog_rows.shape[0]-sample_length) # random starting point of a sequence #3000 long is 30 seconds of data. 6000 is one minute of data\n",
        "  sampled_part =dog_rows.iloc[sample_start:(sample_start+sample_length)]  #sample the dataset\n",
        "  return sampled_part"
      ],
      "metadata": {
        "id": "Blq-vL-XB2_q"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell prepares the Finnish dataset by removing unused variables and unused tasks."
      ],
      "metadata": {
        "id": "j4hpFP8MO9LN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "finnish_dog = finnish_dog_master.copy()\n",
        "finnish_dog['GRMS'] = np.sqrt(np.square(finnish_dog['GNeck_x']) +\tnp.square(finnish_dog['GNeck_y']) + np.square(finnish_dog['GNeck_z']))\n",
        "#remove the back IMU data and the undefined movement data\n",
        "\n",
        "finnish_dog = finnish_dog[finnish_dog['Task']!='<undefined>'] #remove the undefined movements\n",
        "finnish_dog = finnish_dog[finnish_dog['Task']!='Task treat-search']\n",
        "\n",
        "#remove the back IMU data and the undefined movement data\n",
        "finnish_dog = finnish_dog.drop(['TestNum','t_sec','ABack_x',\t'ABack_y',\t'ABack_z','ANeck_z', 'GBack_x', 'GBack_y','GBack_z',\n",
        "                                'Behavior_1','Behavior_2',\t'Behavior_3',\t'PointEvent',\n",
        "                                'ANeck_x', 'ANeck_y'], axis = 1)\n",
        "\n",
        "\n",
        "\n",
        " "
      ],
      "metadata": {
        "id": "1yboMIqKGCdu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell creates the features"
      ],
      "metadata": {
        "id": "Zl2i3rMqPYNU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#summarize within dog and task\n",
        "labeled_dog_median = finnish_dog.groupby(['DogID','Task']).apply(my_median)\n",
        "\n",
        "#label moving vs unmoving\n",
        "mask = ((finnish_dog['Task'] == 'Task lie down') | (finnish_dog['Task'] == 'Task sit') |(finnish_dog['Task'] == 'Task stand'))\n",
        "finnish_dog['moving'] = np.where(mask, 0, 1)\n",
        "\n",
        "'''\n",
        "The line below is the labels for the training data. It's a hack--I'm taking median of \n",
        "the moving variable within a task, but within a task moving is all either 0 or 1. \n",
        "'''\n",
        "y = finnish_dog.groupby(['DogID','Task']).median()['moving'].astype(int)\n",
        "\n",
        "\n",
        "\n",
        "#scale within dog by column\n",
        "normalized_X = labeled_dog_median.groupby('DogID').apply(my_scaler)\n",
        "\n"
      ],
      "metadata": {
        "id": "oKoeUsBHJeq1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Minutes of motion function\n"
      ],
      "metadata": {
        "id": "-PTIyd0CKXQ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def min_of_motion(dog_id,window_size,df): #df is the dataframe of raw IMU data\n",
        "\n",
        "  #remove the target dog from the training set.\n",
        "  X_train = normalized_X.drop(index=dog_id)\n",
        "  y_train = y.drop(index=dog_id)\n",
        "\n",
        " # #train the classifier\n",
        "  model = AdaBoostClassifier(n_estimators=100, learning_rate=1 ,random_state=5)\n",
        "  model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "  unlabeled_dog = df[df['DogID']==dog_id]   #keep only the target dog's data\n",
        "\n",
        "  #calc the number of windows, but losing a few seconds on the end if there isn't a complete window \n",
        "  num_windows = int(unlabeled_dog.shape[0]/(window_size*100)) #the 100 coverts to Hz\n",
        "\n",
        "  unlabeled_dog = unlabeled_dog.iloc[:(num_windows*100*window_size)] #\n",
        "\n",
        "  \n",
        "  #this makes a list of integers that is the largest divisor of n seconds the length of simulated dog \n",
        "  #there will be some of the simulated dog that doesn't fit\n",
        "  values = [x for x in range(0,num_windows)] \n",
        "\n",
        "\n",
        "  #repeats the window many times to make the windows.\n",
        "  # and sorts the windows so all the 1's are first, 2's are second and so on\n",
        "  values_sorted = np.sort(np.resize(values,unlabeled_dog.shape[0]))  \n",
        "\n",
        "\n",
        "  #make the new columns of windows. This way avoid a copy over problem\n",
        "  unlabeled_dog.insert(2, \"windows\", values_sorted, True)\n",
        "\n",
        "\n",
        "  #calculate the true minutes moving from the test dataset. This is used later\n",
        "  simul_true_minutes = unlabeled_dog['moving'].sum()/100/60\n",
        "  \n",
        "  #drop unused columns. May have to change this if I import a file that doesn't have \"moving\"\n",
        "  unlabeled_dog.drop(labels=['DogID','moving','Task'], axis=1, inplace=True) #this drops the old row numbers \n",
        "\n",
        "  #Already selected on dog_id\n",
        "  X_sim = unlabeled_dog.groupby(['windows']).apply(my_median)\n",
        "  X_sim = X_sim.drop('windows',axis=1)\n",
        "\n",
        "  \n",
        "  #normalize\n",
        "  X_sim = (X_sim-X_sim.min())/(X_sim.max()-X_sim.min())\n",
        "\n",
        "  \n",
        "  y_pred_simul = model.predict(X_sim) #predictions from the classifter for whole simulated dog\n",
        "\n",
        "\n",
        "  simul_predicted_minutes = y_pred_simul.sum()*window_size/60   #the /60 converts from seconds to minutes\n",
        "  \n",
        "  return [simul_predicted_minutes, simul_true_minutes,y_pred_simul.shape[0]*window_size/60]"
      ],
      "metadata": {
        "id": "S7IP5BT5Lzms"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##This cell generates the simulated data"
      ],
      "metadata": {
        "id": "Q5TbMwy7Rj3Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "#define the output dataframe. It will hold all the dogs' minute counts\n",
        "out_df = pd.DataFrame(columns=['Dogid','pred_min','true_min','sample_length_min'])\n",
        "\n",
        "\n",
        "#60480000  seven days 100hz\n",
        "#8640000 one day 100Hz\n",
        "# 386400 about an hour , so, 3*386400 is three hours\n",
        "\n",
        "NUMBER_OBS_HZ = 3*386400    #change this number to get longer or shorter clinical trial \n",
        "\n",
        "WINDOW_SIZE = 7   #the widow size in seconds. Change here. \n",
        "\n",
        "TASK_LIST = ['Task walk', 'Task sit', 'Task trot', 'Task lie down', 'Task play', 'Task stand', 'Task treat-search']\n",
        "\n",
        "TASK_PROBABILITIES = [0.0,0.0,0.0,0.5,0.5,0.0,0.0]  #ordering matches TASK_LIST. The numbers add to 1.\n",
        "\n",
        "'''\n",
        "list of dogs to simulate. For longer simulations use fewer dogs to save time. For example, DOG_ID_LIST =[16, 18]. DOG_ID_LIST = finnish_dog['DogID'].unique() \n",
        "is all the dogs. Note that the dog IDs start at 16 and skip some numbers. \n",
        "'''\n",
        "DOG_ID_LIST = finnish_dog['DogID'].unique() \n",
        "\n",
        "\n",
        "for j in DOG_ID_LIST: #loop over the dogs, leaving one out at a time\n",
        "  print(j)  #print the current dog ID just to keep track of how long the loop is taking\n",
        "  \n",
        "  \n",
        "  #An empty datframe that will temporarily hold a single dog's simulated data, which is IMU data at 100 Hz\n",
        "  simul_dog_raw = pd.DataFrame()\n",
        "\n",
        "  while (simul_dog_raw.shape[0])<NUMBER_OBS_HZ:\n",
        "      draw_task = np.random.choice(a=TASK_LIST,size=1,replace=True, p=TASK_PROBABILITIES)    #draw random tasks\n",
        "\n",
        "      simul_dog_raw = pd.concat([simul_dog_raw,sample_movement(j,draw_task[0])])      #sample the specificied task randomly and concat to make long\n",
        "  \n",
        "  \n",
        "  #identify task as moving vs stationary. This is needed here for the time calculations at the end\n",
        "  mask2 = ((simul_dog_raw['Task'] == 'Task lie down') | (simul_dog_raw['Task'] == 'Task sit') |(simul_dog_raw['Task'] == 'Task stand'))\n",
        "  simul_dog_raw['moving'] = np.where(mask2, 0, 1)\n",
        "  \n",
        "\n",
        "  \n",
        "  simul_dog_minutes = min_of_motion(j,WINDOW_SIZE,simul_dog_raw) #Find the number of Minutes of Motion for dog j\n",
        "\n",
        "  out_df = pd.concat([out_df,\n",
        "                     pd.DataFrame.from_dict([{\"Dogid\" :j,\n",
        "                                    \"pred_min\": simul_dog_minutes[0],\n",
        "                                    \"true_min\": simul_dog_minutes[1],\n",
        "                                    \"sample_length_min\":simul_dog_minutes[2] }])])\n",
        "  \n"
      ],
      "metadata": {
        "id": "9RBCe1eHJiKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#write the output file"
      ],
      "metadata": {
        "id": "0Wq_KqmNBCH1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#path = \"your_path\"\n",
        "#out_df.to_csv(path)"
      ],
      "metadata": {
        "id": "plqoe1bi_lmH"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Statistical Analysis"
      ],
      "metadata": {
        "id": "HTdniOcRpEwx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Glance at the output file of predicted and true active minutes, and total time\n",
        "out_df.head()"
      ],
      "metadata": {
        "id": "yjzifSwfCYlA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "d8629586-4a75-4ba0-9303-84da655b7d88"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Dogid    pred_min    true_min sample_length_min\n",
              "0    16  125.533333  113.177333        197.516667\n",
              "0    18        98.7    102.1065        193.666667\n",
              "0    19       64.05      86.645        193.316667\n",
              "0    20  110.716667  112.385333        195.883333\n",
              "0    21        91.0     91.4985            194.25"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dogid</th>\n",
              "      <th>pred_min</th>\n",
              "      <th>true_min</th>\n",
              "      <th>sample_length_min</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>16</td>\n",
              "      <td>125.533333</td>\n",
              "      <td>113.177333</td>\n",
              "      <td>197.516667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>18</td>\n",
              "      <td>98.7</td>\n",
              "      <td>102.1065</td>\n",
              "      <td>193.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>64.05</td>\n",
              "      <td>86.645</td>\n",
              "      <td>193.316667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20</td>\n",
              "      <td>110.716667</td>\n",
              "      <td>112.385333</td>\n",
              "      <td>195.883333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>21</td>\n",
              "      <td>91.0</td>\n",
              "      <td>91.4985</td>\n",
              "      <td>194.25</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Summaries of active minutes, over dog\n",
        "out_df.astype(float).describe()"
      ],
      "metadata": {
        "id": "f4wFS7hINIEn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "1ea17042-c878-4d64-9a15-05b0f5036636"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           Dogid    pred_min    true_min  sample_length_min\n",
              "count  45.000000   45.000000   45.000000          45.000000\n",
              "mean   45.400000   99.495926   99.254100         194.877407\n",
              "std    17.411334   17.436483   13.616988           1.293008\n",
              "min    16.000000   64.050000   64.325667         193.200000\n",
              "25%    29.000000   89.950000   91.498500         193.900000\n",
              "50%    47.000000  102.316667   99.546667         194.483333\n",
              "75%    59.000000  110.600000  106.849000         195.650000\n",
              "max    74.000000  136.966667  134.652333         198.100000"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dogid</th>\n",
              "      <th>pred_min</th>\n",
              "      <th>true_min</th>\n",
              "      <th>sample_length_min</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>45.000000</td>\n",
              "      <td>45.000000</td>\n",
              "      <td>45.000000</td>\n",
              "      <td>45.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>45.400000</td>\n",
              "      <td>99.495926</td>\n",
              "      <td>99.254100</td>\n",
              "      <td>194.877407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>17.411334</td>\n",
              "      <td>17.436483</td>\n",
              "      <td>13.616988</td>\n",
              "      <td>1.293008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>16.000000</td>\n",
              "      <td>64.050000</td>\n",
              "      <td>64.325667</td>\n",
              "      <td>193.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>29.000000</td>\n",
              "      <td>89.950000</td>\n",
              "      <td>91.498500</td>\n",
              "      <td>193.900000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>47.000000</td>\n",
              "      <td>102.316667</td>\n",
              "      <td>99.546667</td>\n",
              "      <td>194.483333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>59.000000</td>\n",
              "      <td>110.600000</td>\n",
              "      <td>106.849000</td>\n",
              "      <td>195.650000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>74.000000</td>\n",
              "      <td>136.966667</td>\n",
              "      <td>134.652333</td>\n",
              "      <td>198.100000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Summaries of the raw difference in active minutes, predicted - true\n",
        "pd.DataFrame((out_df['pred_min']-out_df['true_min'])).astype(float).describe()"
      ],
      "metadata": {
        "id": "Sz-0mTbMXaKy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "5c71ac38-bb45-4c1f-9117-359513a324ac"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               0\n",
              "count  45.000000\n",
              "mean    0.241826\n",
              "std    10.410718\n",
              "min   -23.011167\n",
              "25%    -3.327167\n",
              "50%    -0.160333\n",
              "75%     2.475167\n",
              "max    39.769167"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>45.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.241826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>10.410718</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-23.011167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-3.327167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-0.160333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2.475167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>39.769167</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Summaries of the proportion: of difference in minutes divided by the true number of active minutes\n",
        "pd.DataFrame(((out_df['pred_min']-out_df['true_min'])/out_df['true_min'])).astype(float).describe()"
      ],
      "metadata": {
        "id": "xVfLGySvjBcQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "ee3d6b62-ae82-47cc-91cb-388efa14e181"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               0\n",
              "count  45.000000\n",
              "mean    0.001944\n",
              "std     0.113411\n",
              "min    -0.260777\n",
              "25%    -0.032685\n",
              "50%    -0.001346\n",
              "75%     0.025384\n",
              "max     0.409158"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>45.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.001944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.113411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-0.260777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-0.032685</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-0.001346</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.025384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.409158</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Summaries of the proportion: of difference in minutes divided by the TOTAL number of minutes, active and stationary\n",
        "pd.DataFrame((out_df['pred_min']-out_df['true_min'])/out_df['sample_length_min']).astype(float).describe()"
      ],
      "metadata": {
        "id": "F-NkuoabzwO5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "4b6e5116-a344-465f-a7b6-8476f84be77a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               0\n",
              "count  45.000000\n",
              "mean    0.001206\n",
              "std     0.053505\n",
              "min    -0.117614\n",
              "25%    -0.017016\n",
              "50%    -0.000816\n",
              "75%     0.012696\n",
              "max     0.204978"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>45.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.001206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.053505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-0.117614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-0.017016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-0.000816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.012696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.204978</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pairwise t-test to compare predicted and true minutes. It's really the wrong test. An equivalence test would be better. "
      ],
      "metadata": {
        "id": "2_TDAZz4CnDX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.stats as stats\n",
        "\n",
        "stats.ttest_rel(out_df['pred_min'], out_df['true_min'])"
      ],
      "metadata": {
        "id": "WBqWwhkujINR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acb1e794-baf1-444e-a0ea-2ee6e39aecd9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ttest_relResult(statistic=0.15582188153314472, pvalue=0.8768861297819946)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wilcoxon signed-rank test to compare predicted and true minutes. It's really the wrong test. An equivalence test would be better. "
      ],
      "metadata": {
        "id": "rJxKkmA7Cqog"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import wilcoxon\n",
        "res = wilcoxon((out_df['pred_min']-out_df['true_min']),alternative='greater')\n",
        "res.statistic, res.pvalue"
      ],
      "metadata": {
        "id": "R44LS4NnjLe8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af5f8d89-671e-4eb2-e7a5-b06c42764602"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(490.0, 0.6218745194189702)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The time length of the clinical trial"
      ],
      "metadata": {
        "id": "MwPpj9YvCc2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('minutes:' , NUMBER_OBS_HZ/100/60)\n",
        "print('hours:' ,NUMBER_OBS_HZ/100/60/60)\n",
        "print('days:' ,NUMBER_OBS_HZ/100/60/60/24)"
      ],
      "metadata": {
        "id": "-2pD32XujWGL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6cb7973-6c5f-41e3-ee1f-934c4829e5b1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "minutes: 193.2\n",
            "hours: 3.2199999999999998\n",
            "days: 0.13416666666666666\n"
          ]
        }
      ]
    }
  ]
}